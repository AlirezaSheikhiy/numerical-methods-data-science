{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Linear Regression</br>using Moore-Penrose Pseudoinverse</br>and K-Fold Cross-Validation </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Writing required methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Generator Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_data_generator(size=(1, 1), noise=0.1, seed = 100):\n",
    "    n = size[0]\n",
    "    p = size[1]\n",
    "    np.random.seed(seed=seed)\n",
    "    X = np.random.rand(n, p)\n",
    "    coefficients = np.random.rand(p, 1)\n",
    "    y = X.dot(coefficients) + noise * np.random.randn(n, 1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Moore-Penrose Pseudo Inverse Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moore_penrose_inv(A):\n",
    "    U, s, VT = np.linalg.svd(A)\n",
    "    S = np.zeros(A.shape)\n",
    "    np.fill_diagonal(S, s)\n",
    "    S_plus = S.T\n",
    "    for i in range(np.linalg.matrix_rank(A)):\n",
    "        S_plus[i, i] = 1 / S_plus[i, i]\n",
    "    A_plus = VT.T @ S_plus @ U.T\n",
    "    return A_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating matrix `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bar, y_bar = linear_data_generator(size=(100, 5), noise=0.1, seed=77)\n",
    "X = X_bar.T @ X_bar\n",
    "y = X_bar.T @ y_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting them to a `DataFrame` to display our data in a table format for improved clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature 1</th>\n",
       "      <th>feature 2</th>\n",
       "      <th>feature 3</th>\n",
       "      <th>feature 4</th>\n",
       "      <th>feature 5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample 1</th>\n",
       "      <td>31.042075</td>\n",
       "      <td>24.299935</td>\n",
       "      <td>23.235161</td>\n",
       "      <td>20.245869</td>\n",
       "      <td>26.004368</td>\n",
       "      <td>81.215247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample 2</th>\n",
       "      <td>24.299935</td>\n",
       "      <td>33.095042</td>\n",
       "      <td>24.171426</td>\n",
       "      <td>21.536074</td>\n",
       "      <td>27.096102</td>\n",
       "      <td>86.012863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample 3</th>\n",
       "      <td>23.235161</td>\n",
       "      <td>24.171426</td>\n",
       "      <td>30.195341</td>\n",
       "      <td>19.753527</td>\n",
       "      <td>24.200142</td>\n",
       "      <td>79.968980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample 4</th>\n",
       "      <td>20.245869</td>\n",
       "      <td>21.536074</td>\n",
       "      <td>19.753527</td>\n",
       "      <td>27.230340</td>\n",
       "      <td>23.301305</td>\n",
       "      <td>74.318278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample 5</th>\n",
       "      <td>26.004368</td>\n",
       "      <td>27.096102</td>\n",
       "      <td>24.200142</td>\n",
       "      <td>23.301305</td>\n",
       "      <td>35.777421</td>\n",
       "      <td>86.539583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature 1  feature 2  feature 3  feature 4  feature 5     target\n",
       "sample 1  31.042075  24.299935  23.235161  20.245869  26.004368  81.215247\n",
       "sample 2  24.299935  33.095042  24.171426  21.536074  27.096102  86.012863\n",
       "sample 3  23.235161  24.171426  30.195341  19.753527  24.200142  79.968980\n",
       "sample 4  20.245869  21.536074  19.753527  27.230340  23.301305  74.318278\n",
       "sample 5  26.004368  27.096102  24.200142  23.301305  35.777421  86.539583"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=X, columns=[f\"feature {i+1}\" for i in range(len(X[0]))], index=[f\"sample {i+1}\" for i in range(len(X))])\n",
    "df[\"target\"] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing coefficients matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.insert(X, 0, np.ones(len(X)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Performing Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type 1: Linear Regression using `train_test_split` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `train_test_split` to split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    A, y, test_size=0.2, random_state=77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the pseudo inverse of `X_train` matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_plus = moore_penrose_inv(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the Linear Regression coefficients using `train` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_hat = X_train_plus @ y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the `y` vector for the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = X_train @ beta_hat\n",
    "y_pred_test = X_test @ beta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the Errors for both train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_train = np.linalg.norm(y_train - y_pred_train, ord=2)\n",
    "norm_test = np.linalg.norm(y_test - y_pred_test, ord=2)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm Error for Train data: 3.759838749409412e-14\n",
      "Norm Error for Test data: 0.7751584832372913\n",
      "Mean Squared Error for Train data: 3.534096855390133e-28\n",
      "Mean Squared Error for Test data: 0.600870674134738\n"
     ]
    }
   ],
   "source": [
    "print(f\"Norm Error for Train data: {norm_train}\")\n",
    "print(f\"Norm Error for Test data: {norm_test}\")\n",
    "print(f\"Mean Squared Error for Train data: {mse_train}\")\n",
    "print(f\"Mean Squared Error for Test data: {mse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type 2: Linear Regression using `KFold` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing KFold object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list = []\n",
    "norm_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(A):\n",
    "    X_train, X_test = A[train_index], A[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train_plus = moore_penrose_inv(X_train)\n",
    "    \n",
    "    beta_hat = X_train_plus @ y_train\n",
    "    \n",
    "    y_pred = X_test @ beta_hat\n",
    "    \n",
    "    error = np.linalg.norm(y_test - y_pred, ord=2)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    norm_list.append(error)\n",
    "    mse_list.append(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The norms error and mse table for each fold:\n",
      "\n",
      " Folds  Norms Error       MSE\n",
      "     1     0.775158  0.600871\n",
      "     2     3.224640 10.398303\n",
      "     3     1.755594  3.082112\n",
      "     4     0.694851  0.482818\n",
      "     5     3.327010 11.068993\n",
      "\n",
      "Average Norms: 1.955450684986431\n",
      "Average Mean Squared Error: 5.126619362242911\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data={\"Folds\": range(1, k+1),\n",
    "                              \"Norms Error\": norm_list,\n",
    "                              \"MSE\": mse_list})\n",
    "print(\"The norms error and mse table for each fold:\\n\")\n",
    "print(df.to_string(index=False), end=\"\\n\\n\")\n",
    "print(\"Average Norms:\", np.mean(norm_list))\n",
    "print(\"Average Mean Squared Error:\", np.mean(mse_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
